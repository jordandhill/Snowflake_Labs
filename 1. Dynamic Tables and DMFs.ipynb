{
 "metadata": {
  "kernelspec": {
   "display_name": "Streamlit Notebook",
   "name": "streamlit"
  }
 },
 "nbformat_minor": 5,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2d4eef9d-1863-4c7e-b759-ea186910849a",
   "metadata": {
    "name": "cell1",
    "collapsed": false
   },
   "source": "# DYNAMIC TABLES\n\nDynamic tables are a declarative way of defining your data pipeline in Snowflake. It will continuously and automatically materialize the result of that query as a table. Dynamic Tables can join and aggregate across multiple source objects and *incrementally* update results as sources change.\n\nDynamic Tables can also be chained together to create a DAG for more complex data pipelines.\n\n![image](https://quickstarts.snowflake.com/guide/getting_started_with_dynamic_tables/img/b268e50e6bedab07.jpg)\n\n\n\n## What You'll Build Today\n- A continuous data pipeline using Dynamic tables\n- Manage and monitor Dynamic tables\n- Add some Data Quality Metrics"
  },
  {
   "cell_type": "code",
   "id": "b2f7e7a4-d1f4-4ad9-b68b-14e7d96feb28",
   "metadata": {
    "language": "sql",
    "name": "cell31",
    "collapsed": false
   },
   "outputs": [],
   "source": "--first create your own schema to work in!\ncreate schema if not exists MY_NAME ;\nuse schema MY_NAME;\n---this should be your name!!\nselect current_database(), current_schema();",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "8d50cbf4-0c8d-4950-86cb-114990437ac9",
   "metadata": {
    "language": "sql",
    "name": "cell2",
    "collapsed": false
   },
   "source": "---step one create sample data using a python UDF function\n\ncreate or replace function gen_cust_info(num_records number)\nreturns table (custid number(10), cname varchar(100), spendlimit number(10,2))\nlanguage python\nruntime_version=3.8\nhandler='CustTab'\npackages = ('Faker')\nas $$\nfrom faker import Faker\nimport random\n\nfake = Faker()\n# Generate a list of customers  \n\nclass CustTab:\n    # Generate multiple customer records\n    def process(self, num_records):\n        customer_id = 1000 # Starting customer ID                 \n        for _ in range(num_records):\n            custid = customer_id + 1\n            cname = fake.name()\n            spendlimit = round(random.uniform(1000, 10000),2)\n            customer_id += 1\n            yield (custid,cname,spendlimit)\n\n$$;\n\ncreate or replace table cust_info as select * from table(gen_cust_info(1000)) order by 1;",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "80c8bcee-f01a-4512-8ee8-e9c0acfa72c3",
   "metadata": {
    "language": "sql",
    "name": "cell3",
    "collapsed": false
   },
   "outputs": [],
   "source": "--did we get data?\nselect * from cust_info limit 5",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "28306a90-7441-478c-811e-6c0051c48de6",
   "metadata": {
    "language": "sql",
    "name": "cell4",
    "collapsed": false
   },
   "outputs": [],
   "source": "--repeat for the other tables in our pipeline\ncreate or replace function gen_prod_inv(num_records number)\nreturns table (pid number(10), pname varchar(100), stock number(10,2), stockdate date)\nlanguage python\nruntime_version=3.8\nhandler='ProdTab'\npackages = ('Faker')\nas $$\nfrom faker import Faker\nimport random\nfrom datetime import datetime, timedelta\nfake = Faker()\n\nclass ProdTab:\n    # Generate multiple product records\n    def process(self, num_records):\n        product_id = 100 # Starting customer ID                 \n        for _ in range(num_records):\n            pid = product_id + 1\n            pname = fake.catch_phrase()\n            stock = round(random.uniform(500, 1000),0)\n            # Get the current date\n            current_date = datetime.now()\n            \n            # Calculate the maximum date (3 months from now)\n            min_date = current_date - timedelta(days=90)\n            \n            # Generate a random date within the date range\n            stockdate = fake.date_between_dates(min_date,current_date)\n\n            product_id += 1\n            yield (pid,pname,stock,stockdate)\n\n$$;\n\ncreate or replace table prod_stock_inv as select * from table(gen_prod_inv(100)) order by 1;\n\ncreate or replace function gen_cust_purchase(num_records number,ndays number)\nreturns table (custid number(10), purchase variant)\nlanguage python\nruntime_version=3.8\nhandler='genCustPurchase'\npackages = ('Faker')\nas $$\nfrom faker import Faker\nimport random\nfrom datetime import datetime, timedelta\n\nfake = Faker()\n\nclass genCustPurchase:\n    # Generate multiple customer purchase records\n    def process(self, num_records,ndays):       \n        for _ in range(num_records):\n            c_id = fake.random_int(min=1001, max=1999)\n            \n            #print(c_id)\n            customer_purchase = {\n                'custid': c_id,\n                'purchased': []\n            }\n            # Get the current date\n            current_date = datetime.now()\n            \n            # Calculate the maximum date (days from now)\n            min_date = current_date - timedelta(days=ndays)\n            \n            # Generate a random date within the date range\n            pdate = fake.date_between_dates(min_date,current_date)\n            \n            purchase = {\n                'prodid': fake.random_int(min=101, max=199),\n                'quantity': fake.random_int(min=1, max=5),\n                'purchase_amount': round(random.uniform(10, 1000),2),\n                'purchase_date': pdate\n            }\n            customer_purchase['purchased'].append(purchase)\n            \n            #customer_purchases.append(customer_purchase)\n            yield (c_id,purchase)\n\n$$;\n\n-- Create table and insert records \ncreate or replace table salesdata as select * from table(gen_cust_purchase(10000,10));\n\n\n\n",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "ce921d87-b3b9-4be6-b440-ef30cb0c1805",
   "metadata": {
    "name": "cell5",
    "collapsed": false
   },
   "source": "This completes our sample data stored in raw base tables. In real world, you will load this data into Snowflake either using COPY COMMAND, connectors, Snowpipe or Snowpipe Streaming"
  },
  {
   "cell_type": "code",
   "id": "13a06e74-b406-43cd-9879-f15a3b9fd631",
   "metadata": {
    "language": "sql",
    "name": "cell6",
    "collapsed": false
   },
   "outputs": [],
   "source": "--Check if there is data in all 3 raw tables -\n\n-- customer information table, each customer has spending limits\nselect * from cust_info limit 5;\n\n-- product stock table, each product has stock level from fulfilment day\n\nselect * from prod_stock_inv limit 5;\n\n-- sales data for products purchsaed online by various customers\nselect * from salesdata limit 5;",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "2177e297-7df4-41ce-bf2e-50dcd29b4cef",
   "metadata": {
    "name": "cell7",
    "collapsed": false
   },
   "source": ""
  },
  {
   "cell_type": "markdown",
   "id": "4d932e77-040e-4be7-86a5-5bf374cf2cf5",
   "metadata": {
    "name": "cell8",
    "collapsed": false
   },
   "source": "## Problem Statement\nLet's assume that you are a data engineer at an online retail company, where a wide array of products is sold. In this role, we collect customer purchase and product sales data, initially storing it in a raw data table. Our primary tasks involve creating a continuous data pipeline for generating sales reports and validate the data.\n\n## Data Pipeline Architecture\n![](https://i.postimg.cc/3NCyXC6C/Screenshot-2024-06-07-at-4-45-04-PM.png)"
  },
  {
   "cell_type": "markdown",
   "id": "6118497c-12cd-4377-be68-1df9c82c1350",
   "metadata": {
    "name": "cell10",
    "collapsed": false
   },
   "source": "Let's create our first Dynamic Table. For the first step in the pipeline we will extract the sales information from the salesdata table and join it with customer information to build the customer_sales_data_history, note that *we are extracting raw json data(schema on read)* and transforming it into meaningful columns and data types.\n\n"
  },
  {
   "cell_type": "markdown",
   "id": "a996f563-e8ba-4416-b273-59d333a5deed",
   "metadata": {
    "name": "cell11",
    "collapsed": false
   },
   "source": "[Increment Refresh is Important!](https://docs.snowflake.com/en/user-guide/dynamic-tables-refresh#supported-queries-in-incremental-refresh)"
  },
  {
   "cell_type": "code",
   "id": "b27bb7b3-f36c-49cd-9a48-837ab176f764",
   "metadata": {
    "language": "sql",
    "name": "cell9",
    "collapsed": false
   },
   "outputs": [],
   "source": "\nCREATE OR REPLACE DYNAMIC TABLE customer_sales_data_history\n    LAG='DOWNSTREAM'\n    WAREHOUSE=COMPUTE_WH_FOR_LAB\nAS\nselect \n    s.custid as customer_id,\n    c.cname as customer_name,\n    s.purchase:\"prodid\"::number(5) as product_id,\n    s.purchase:\"purchase_amount\"::number(10) as saleprice,\n    s.purchase:\"quantity\"::number(5) as quantity,\n    s.purchase:\"purchase_date\"::date as salesdate\nfrom\n    cust_info c inner join salesdata s on c.custid = s.custid\n;",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "bd9faad9-36cd-4bd0-8a1b-cd55ded4dab7",
   "metadata": {
    "name": "cell14",
    "collapsed": false
   },
   "source": "## Target lag is specified in one of following ways:\n\n- Measure of freshness: Defines the maximum amount of time that the dynamic tableâ€™s content should lag behind updates to the base tables.\n\n    The following example sets the dynamic table to refresh and maintain freshness every hour:\n\n    ALTER DYNAMIC TABLE product SET TARGET_LAG = '1 hour';\n\n- Downstream: Specifies that the dynamic table should refresh on demand when other dependent dynamic tables refresh. This refresh can be triggered by a manual or scheduled refresh of a downstream dynamic table.\n\n    In the following example, refresh is based on other downstream dynamic tables:\n\n    ALTER DYNAMIC TABLE product SET TARGET_LAG = DOWNSTREAM;\n"
  },
  {
   "cell_type": "code",
   "id": "e513e376-c35e-4625-9db8-e349240b041a",
   "metadata": {
    "language": "sql",
    "name": "cell13",
    "collapsed": false
   },
   "outputs": [],
   "source": "-- quick sanity check\nselect * from customer_sales_data_history limit 10;",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "72a77759-504e-47a5-86da-782716dd0957",
   "metadata": {
    "language": "sql",
    "name": "cell12",
    "collapsed": false
   },
   "outputs": [],
   "source": "\nselect count(*) from customer_sales_data_history;",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "a461d6e6-9ab4-48d0-a7bc-903833d8acb4",
   "metadata": {
    "name": "cell16",
    "collapsed": false
   },
   "source": "Now, let's combine these results with the product table, we can even encorporate window functions"
  },
  {
   "cell_type": "code",
   "id": "124aad39-8d46-4396-bf7b-1e9161ed24a1",
   "metadata": {
    "language": "sql",
    "name": "cell15",
    "collapsed": false
   },
   "outputs": [],
   "source": "CREATE OR REPLACE DYNAMIC TABLE salesreport\n    LAG = '1 MINUTE'\n    WAREHOUSE=COMPUTE_WH_FOR_LAB\nAS\n    Select\n        t1.customer_id,\n        t1.customer_name, \n        t1.product_id,\n        p.pname as product_name,\n        t1.saleprice,\n        t1.quantity,\n        (t1.saleprice/t1.quantity) as unitsalesprice,\n        t1.salesdate as CreationTime,\n        customer_id || '-' || t1.product_id  || '-' || t1.salesdate AS CUSTOMER_SK,\n        LEAD(CreationTime) OVER (PARTITION BY t1.customer_id ORDER BY CreationTime ASC) AS END_TIME\n    from \n        customer_sales_data_history t1 inner join prod_stock_inv p \n        on t1.product_id = p.pid\n       \n;",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "dd8fa280-0d85-4a83-9002-2ae6729f5c95",
   "metadata": {
    "language": "sql",
    "name": "cell17",
    "collapsed": false
   },
   "outputs": [],
   "source": "select * from salesreport limit 5;\n",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "eab361af-8316-4dd1-8d2c-a44efc8db960",
   "metadata": {
    "language": "sql",
    "name": "cell18",
    "collapsed": false
   },
   "outputs": [],
   "source": "select count(*) from salesreport;",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "49ba756a-cf79-408a-9785-98aa7dad1a18",
   "metadata": {
    "name": "cell19",
    "collapsed": false
   },
   "source": "Check the UI!  Love a nice looking DAG\n\n__[Monitor Dynamic Tables](https://app.snowflake.com/sfsenorthamerica/demo_jhill/#/compute/history/dynamic-tables)__\n![](https://i.postimg.cc/Gt0D2T1G/DT-UI.png)"
  },
  {
   "cell_type": "code",
   "id": "d94351b8-7fdf-4fa1-9632-456feaa8219a",
   "metadata": {
    "language": "sql",
    "name": "cell21",
    "collapsed": false
   },
   "outputs": [],
   "source": "---can also monitor in SQL\nSELECT * \nFROM \n    TABLE(INFORMATION_SCHEMA.DYNAMIC_TABLE_REFRESH_HISTORY())\nWHERE \n    NAME IN ('SALESREPORT','CUSTOMER_SALES_DATA_HISTORY')\n    -- AND REFRESH_ACTION != 'NO_DATA'\nORDER BY \n    DATA_TIMESTAMP DESC, REFRESH_END_TIME DESC LIMIT 10;",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "87cd26f0-383f-4db4-89d4-6c594fdc12b5",
   "metadata": {
    "language": "sql",
    "name": "cell24",
    "collapsed": false
   },
   "outputs": [],
   "source": "-- Add new records to test out pipeline\ninsert into salesdata select * from table(gen_cust_purchase(10000,2));\n\n-- Check raw base table\nselect count(*) from salesdata;\n",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "4357dea1-0cb1-4a70-95df-791a009da841",
   "metadata": {
    "language": "sql",
    "name": "cell25",
    "collapsed": false
   },
   "outputs": [],
   "source": "-- Check Dynamic Tables after a minute... should grow by 10K\nselect count(*) from salesreport;",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "0630aaa4-1ea2-4481-8686-f451da77b327",
   "metadata": {
    "language": "sql",
    "name": "cell22",
    "collapsed": false
   },
   "outputs": [],
   "source": "--!!!MANUAL REFRESH OF PIPELINE --- can be done from any tool!!!\ninsert into salesdata select * from table(gen_cust_purchase(10000,2));\nalter dynamic table salesreport REFRESH;\n--target ready ASAP\nselect count(*) from salesreport;",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "bade25cb-5485-4f21-899f-e18eec60b9ff",
   "metadata": {
    "language": "sql",
    "name": "cell23"
   },
   "outputs": [],
   "source": "---other useful SQL\n-- Resume the data pipeline\nalter dynamic table salesreport RESUME;\n\n\n-- Suspend the data pipeline\nalter dynamic table salesreport SUSPEND;\n",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "b0f6532a-d702-4ed8-9fa7-97ab1b0fcede",
   "metadata": {
    "name": "cell20",
    "collapsed": false
   },
   "source": "# How About Monitoring My Data???\n## [How about Data Quality Metrics](https://docs.snowflake.com/en/user-guide/data-quality-system-dmfs#system-dmfs) :)"
  },
  {
   "cell_type": "markdown",
   "id": "242cf920-94c1-42ea-b92b-b9b6f9ec2e24",
   "metadata": {
    "name": "cell33",
    "collapsed": false
   },
   "source": "![image](https://i.postimg.cc/QxtbtpwD/mypic.jpg)\n\n"
  },
  {
   "cell_type": "code",
   "id": "aa7cb83f-4347-4120-8dd5-718df17e875a",
   "metadata": {
    "language": "sql",
    "name": "cell37",
    "collapsed": false
   },
   "outputs": [],
   "source": "ALTER TABLE salesdata\n-- SET DATA_METRIC_SCHEDULE = '5 MINUTES';\n  DATA_METRIC_SCHEDULE = 'TRIGGER_ON_CHANGES';",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "81080be5-4a3d-4588-8ae6-284601ebc8cf",
   "metadata": {
    "language": "sql",
    "name": "cell38",
    "collapsed": false
   },
   "outputs": [],
   "source": "ALTER TABLE salesdata ADD DATA METRIC FUNCTION\n  SNOWFLAKE.CORE.NULL_COUNT ON (custid);",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "f6d935e0-52e3-4542-b165-9ce8d4f8ef99",
   "metadata": {
    "language": "sql",
    "name": "cell35",
    "collapsed": false
   },
   "outputs": [],
   "source": "INSERT INTO salesdata VALUES(NULL,NULL)",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "9f8aad46-07b9-49d5-b5ef-37ee12fb8a2a",
   "metadata": {
    "language": "sql",
    "name": "cell34",
    "collapsed": false
   },
   "outputs": [],
   "source": "SELECT SNOWFLAKE.CORE.NULL_COUNT(\n  SELECT custid\n  FROM salesdata\n);",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "5703e1fe-1608-40bc-8515-a2b27e1eddb9",
   "metadata": {
    "language": "sql",
    "name": "cell32",
    "collapsed": false
   },
   "outputs": [],
   "source": "SELECT METRIC_DATABASE, METRIC_NAME, scheduled_time, measurement_time, table_database, table_schema, table_name, metric_name, value, *\nFROM SNOWFLAKE.LOCAL.DATA_QUALITY_MONITORING_RESULTS\nWHERE TRUE\nand table_schema = 'MY_NAME'\nand table_database = 'HOL_TAKETWO'\nLIMIT 100;",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "d177b577-ba71-4f84-be60-16ec20a7116e",
   "metadata": {
    "name": "cell36",
    "collapsed": false
   },
   "source": "# POP QUIZ\n- Remove the null record from the base table salesdata\n- Force a manual refresh of the target DYNAMIC TABLE salesreport\n- Check that the record no long exists using your DATA QUALITY METRIC"
  },
  {
   "cell_type": "code",
   "id": "6d3ce8dc-ec3f-4e8d-99c2-fb04fdb8fbe6",
   "metadata": {
    "language": "sql",
    "name": "cell26"
   },
   "outputs": [],
   "source": "",
   "execution_count": null
  }
 ]
}